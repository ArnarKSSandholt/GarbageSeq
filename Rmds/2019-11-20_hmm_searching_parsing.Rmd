---
title: "HMM search using eggNOG viral data and parsing of output"
author: "LJM"
date: "`r Sys.Date()`"
link-citations: true
bibliography: bibliography.bib
biblio-style: "alpha" #https://www.overleaf.com/learn/latex/Bibtex_bibliography_styles
#csl: "../uppsala-universitet-institutionen-for-biologisk-grundutbildning.csl"
documentclass: report
output:
  bookdown::html_document2:
    highlight: tango
    theme: journal
    split_by: none # only generate a single output page
    self_contained: TRUE
    toc: yes
    toc_float: 
      collapsed: TRUE
      smooth_scroll: TRUE
      print: FALSE
    code_folding: show
    number_sections: TRUE
    code_download: TRUE
  html_document: 
    toc: TRUE
    toc_float: TRUE
    code_folding: show
    highlight: tango
    number_sections: TRUE
    self_contained: TRUE
    smart: TRUE # To be figured out when this is useful
    theme: journal
  pdf_document:
    toc: TRUE
    toc_depth: 2
    highlight: tango # This appears to be the same as default
    number_sections: TRUE
  bookdown::pdf_document2:
    keep_tex: no
    latex_engine: xelatex
    #highlight: pygments #Other options: default, tango, kate, monochrome, espresso, zenburn, haddock, and textmate
    #theme: spacelab
    pandoc_args: ["--variable", "subparagraph",
                "--top-level-division","chapter"] # Could also be section 
---

# Searching with HMMs

Essentially the following code will be run in a sbatch script: 

```{bash eval=FALSE, include=TRUE}
#ml bioinfo-tools hmmer/3.2.1
DATA="../analyses/HMM_scan_using_eggNOG_HMMs/eggNOG_data/HMMs/10239/"
fOTUproteoms_DIR="../analyses/fOTU_proteomes/"
HMMer_OUTPUT_DIR="../analyses/HMM_scan_using_eggNOG_HMMs/hmmsearch_out_viruses/"
TAXID_NO="10239"
read -r -a fOTUproteoms <<< $( find $fOTUproteoms_DIR -name "*.faa" -and -type f -print0 | xargs -0 echo )
echo "fOTUprot" ${#fOTUproteoms[@]}
# Take time of this run
SECONDS=0
read -r -a HMMs <<< $( find $DATA -name "*.hmm" -and -type f -print0 | xargs -0 echo )
for fOTUproteom in "${fOTUproteoms[@]}"; do
  fOTU_FILE=$(echo $(basename "$fOTUproteom"))
  fOTU=$(echo $(basename "$fOTUproteom") | awk -F "." '{print $1}')
  for HMM in "${HMMs[@]}"; do
    HMM_FILE=$(echo $(basename "$HMM"))
    HMM_VARIANT=$(echo $(basename "$HMM") | awk -F "." '{print $1}')
    hmmsearch --cpu 10 --noali --notextw -E 0.1 --domE 0.1 --incE 0.01 --incdomE 0.01 "$HMM" "$fOTUproteom" >> "$HMMer_OUTPUT_DIR""$TAXID_NO""-with-""$fOTU"".out"
  done
done
duration=$SECONDS
echo "$(($duration / 60)) minutes and $(($duration % 60)) seconds elapsed."
```

# Counting number of bins in each fOTU

```{bash eval=FALSE, include=TRUE}
fOTUs="../data/fOTUs.csv"
SCRIPT="../scripts/binCounter.awk"
OUTPUT="../analyses/numBinsfOTU.csv"
cat $fOTUs | awk -F, -v delimiter="," -f $SCRIPT > $OUTPUT
```

# Parse delimited files from hmmsearch output files

```{bash eval=FALSE, include=TRUE}
SCRIPT="../scripts/hmmsearchOutputParser.awk"
eggNOGs="../analyses/HMM_scan_using_eggNOG_HMMs/hmmsearch_out_viruses/"
PARSED="../analyses/HMM_scan_using_eggNOG_HMMs/hmmsearch_out_parsed/"
read -r -a eggNOGarray <<< $( find $eggNOGs -name "*.out" -and -type f -print0 | xargs -0 echo )

SECONDS=0
for eggNOGfile in "${eggNOGarray[@]}"; do
  FILE=$(echo $(basename "$eggNOGfile"))
  fOTU=$(echo $FILE | awk -F "-with-" '{print $2}' | awk -F "." '{print $1}')
  awk -v filename="$FILE" -v delimiter="\t" -v last_col=10 -f "$SCRIPT" "$eggNOGfile" > "$PARSED""$fOTU"".tsv"
done

duration=$SECONDS
echo "$(($duration / 60)) minutes and $(($duration % 60)) seconds elapsed."
```

# Create a csv containing number of sequences per bin

```{bash eval=FALSE, include=TRUE}
BINS="../data/proteoms/"
OUTPUT="../analyses/numSeqsBin.csv"

read -r -a BINS_ARRAY <<< $( find $BINS -name "*.faa" -and -type f -print0 | xargs -0 echo )

# Here the Bin ID is named this way because it's faster to join this data to another later on
printf "%s\n" "Target_Bin_id,Num_of_seqs" >> $OUTPUT

SECONDS=0
for BIN in "${BINS_ARRAY[@]}"; do
  FILE=$(echo $(basename "$BIN"))
  BIN_ID=$(echo $(basename "$FILE") | awk -F "." '{print $1}')
  NUM_SEQS=$(grep -c '>' $BIN)
  printf "%s," "$BIN_ID" >> $OUTPUT
  printf "%s\n" "$NUM_SEQS" >> $OUTPUT
done

duration=$SECONDS
echo "$(($duration / 60)) minutes and $(($duration % 60)) seconds elapsed."

```


# Testing new utilities

## Utility script for parsing eggNOG output files

```{bash eval=FALSE, include=TRUE}
OUTPUT="../analyses/HMM_scan_using_eggNOG_HMMs/hmmsearch_out_viruses/"
FILE="10239-with-cogOTU_1165.out"
SCRIPT="../scripts/hmmsearchOutputParser.awk"
#pcre2grep -M -B 19 -A 11 "^    \d.+$\n(.*\n)*?^Internal pipeline statistics summary:" $OUTPUT1
SECONDS=0
#pcre2grep -M -B 19 -A 11 "^    \d.+$\n(.*\n)*?^Internal pipeline statistics summary:" $OUTPUT4 > test.txt
awk -v filename="$FILE" -v delimiter="\t" -v last_col=10 -f $SCRIPT "$OUTPUT""$FILE"
duration=$SECONDS
echo "$(($duration / 60)) minutes and $(($duration % 60)) seconds elapsed."
```

## Utility script for changing delimiters

The changing of delimiters is from space delimited to a user given delimiter

```{bash eval=FALSE, include=TRUE}
SCRIPT="../scripts/eggNOGdeliminator.awk"
TSV_FILE="Fuselloviridae_10474_annotations.tsv"
# A regex for the linus that should be skipped when adding delimiters in the middle
REGEXP="^#.+"

cat $TSV_FILE | awk -v delimiter=";" -v last_col="4" -v excluded_recs="$REGEXP" -f $SCRIPT
```

## Helper chunk for moving already studied fOTUs

```{bash eval=FALSE, include=TRUE}
STUDIED_fOTUs="../analyses/HMM_scan_using_eggNOG_HMMs/hmmsearch_out_viruses/"
fOTUs="../analyses/fOTU_proteomes/" 
TEMP_STORAGE="../analyses/fOTU_proteomes_studied/"

read -r -a STUDIED_fOTUs_ARRAY <<< $( find $STUDIED_fOTUs -name "*.out" -and -type f -print0 | xargs -0 echo )
for STUDIED_fOTU in "${STUDIED_fOTUs_ARRAY[@]}"; do
  fOTU=$(echo $(basename "$STUDIED_fOTU") | awk -F "." '{print $1}' | awk -F "-with-" '{print $2}')
  mv "$fOTUs""$fOTU"".faa" "$TEMP_STORAGE"
done

```


# Session info

```{r}
sessionInfo()
```


# References
