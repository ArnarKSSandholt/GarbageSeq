---
title: "HMM search output analyses"
author: "LJM"
date: "`r Sys.Date()`"
link-citations: true
bibliography: bibliography.bib
biblio-style: "alpha" #https://www.overleaf.com/learn/latex/Bibtex_bibliography_styles
#csl: "../uppsala-universitet-institutionen-for-biologisk-grundutbildning.csl"
documentclass: report
output:
  bookdown::html_document2:
    highlight: tango
    theme: journal
    split_by: none # only generate a single output page
    self_contained: TRUE
    toc: yes
    toc_float: 
      collapsed: TRUE
      smooth_scroll: TRUE
      print: FALSE
    code_folding: show
    number_sections: TRUE
    code_download: TRUE
  html_document: 
    toc: TRUE
    toc_float: TRUE
    code_folding: show
    highlight: tango
    number_sections: TRUE
    self_contained: TRUE
    smart: TRUE # To be figured out when this is useful
    theme: journal
  pdf_document:
    toc: TRUE
    toc_depth: 2
    highlight: tango # This appears to be the same as default
    number_sections: TRUE
  bookdown::pdf_document2:
    keep_tex: no
    latex_engine: xelatex
    #highlight: pygments #Other options: default, tango, kate, monochrome, espresso, zenburn, haddock, and textmate
    #theme: spacelab
    pandoc_args: ["--variable", "subparagraph",
                "--top-level-division","chapter"] # Could also be section 
---

# Analysing hmm output data 

```{r message=FALSE}
library(tidyverse)

hit_percentage <- vector()

path_to_data <- "../analyses/HMM_scan_using_eggNOG_HMMs/hmmsearch_out_parsed/"

files <- list.files(path = path_to_data, pattern = "*.tsv", recursive=FALSE)

fOTUbinNums <- read_csv(file = "../analyses/numBinsfOTU.csv", 
                          col_types = "ci", 
                          col_names = c("fOTU_name",
                                        "num_bins"))
egg_nog_cats <- read_tsv(file = "../data/annotations/10239_annotations.tsv", 
                         col_types = "fcfc", 
                         col_names = c("taxid","hmm_profile_id",
                                       "egg_nog_category",
                                       "hmm_description")) %>%
  # Drop taxid because it's uninteresting
  select(.,-taxid)

num_seqs <- read_csv(file = "../analyses/numSeqsBin.csv", 
                          col_types = "ci")

# Read in some data
tsv_names <- c("fOTU_name",
               "hmm_profile_id",
               "inside_inclusion_threshold",
               "Target_Bin_id",
               "Target_Seq_id",
               "full_sequence_e-value",
               "full_sequence_score",
               "full_sequence_bias",
               "best_one_domain_e-value",
               "best_one_domain_score",
               "best_one_domain_bias",
               "exp",
               "N",
               "description")

for(fOTU_file in files) {
  
  path_file <- paste(path_to_data,fOTU_file, sep = "")
  
  fOTU <- read_tsv(file = path_file, 
                   col_types = "cclcfdddddddic", 
                   col_names = tsv_names)
  
  # Check if there were empty bins
  fOTU_first_term <- fOTU %>%
    pull(fOTU_name)
  fOTU_first_term <- fOTU_first_term[1]
  # The empty bins had "dummy" as the first word in the first line
  if(fOTU_first_term == "dummy"){
    hit_percentage <- c(hit_percentage,0.0)
    next
  }
  
  # Make a big data table out of these three tibbles by left joining 
  fOTU <- left_join(fOTU, egg_nog_cats, by = "hmm_profile_id") %>%
    left_join(., fOTUbinNums, by = "fOTU_name") %>%
    # Remove values that were outside inclusion threshold
    filter(.,inside_inclusion_threshold) %>%
    # Drop inside_inclusion_threshold now that it has done its duty
    select(.,-inside_inclusion_threshold)
  
  # Find how many hits there are to each bin
  numHits <- fOTU %>%
    count(.,Target_Bin_id) %>%
    rename(.,Num_hits = n)
  
  # Add num hits beside each bin
  fOTU <- left_join(fOTU, numHits, by = "Target_Bin_id")
  
  # Add total number of sequences in each bin
  fOTU <- left_join(fOTU, num_seqs, by = "Target_Bin_id")
  
  # Count how many unique hits to bins there are
  fOTU_vec_len <- fOTU %>%
    distinct(.,Target_Bin_id) %>%
    pull(Target_Bin_id) %>%
    length()
  
  # Grab the total number of bins in the fOTU
  fOTU_tot_num_bins <- fOTU %>%
    pull(num_bins)
  fOTU_tot_num_bins <- fOTU_vec_len/fOTU_tot_num_bins[1]
  
  # Append the value to a vector
  hit_percentage <- c(hit_percentage,fOTU_tot_num_bins)
}

# Create finally a tibble from the vector
hits <- tibble(hit_percentage)

```

Maybe of interest is to group by all the target bins and look for how many unique matches there are between HMMs and seqs.

```{r}
#fOTU %>%
#  group_by(Target_Bin_id) %>%
#  n_distinct(Target_Seq_id) %>%
#  count()
```



# Visualise the data

The following graph depicts how large percentage of bins in fOTU have at least one hit from viral HMM profiles with e-value less than 0.01.

```{r}
qplot(hit_percentage, data = hits, binwidth = 0.01)
```


# Session info

```{r}
sessionInfo()
```


# References
