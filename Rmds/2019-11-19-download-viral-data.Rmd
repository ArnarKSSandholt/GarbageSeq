---
title: "Download Viral Data and preprocess it"
author: "LJM"
date: "`r Sys.Date()`"
link-citations: true
bibliography: bibliography.bib
biblio-style: "alpha" #https://www.overleaf.com/learn/latex/Bibtex_bibliography_styles
#csl: "../uppsala-universitet-institutionen-for-biologisk-grundutbildning.csl"
documentclass: report
output:
  bookdown::html_document2:
    highlight: tango
    theme: journal
    split_by: none # only generate a single output page
    self_contained: TRUE
    toc: yes
    toc_float: 
      collapsed: TRUE
      smooth_scroll: TRUE
      print: FALSE
    code_folding: show
    number_sections: TRUE
    code_download: TRUE
  html_document: 
    toc: TRUE
    toc_float: TRUE
    code_folding: show
    highlight: tango
    number_sections: TRUE
    self_contained: TRUE
    smart: TRUE # To be figured out when this is useful
    theme: journal
  pdf_document:
    toc: TRUE
    toc_depth: 2
    highlight: tango # This appears to be the same as default
    number_sections: TRUE
  bookdown::pdf_document2:
    keep_tex: no
    latex_engine: xelatex
    #highlight: pygments #Other options: default, tango, kate, monochrome, espresso, zenburn, haddock, and textmate
    #theme: spacelab
    pandoc_args: ["--variable", "subparagraph",
                "--top-level-division","chapter"] # Could also be section 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Acquiring viral EggNOG data

In order to utilise EggNOGs viral data for classification of fOTUs, certain pieces of data should be downloaded from the database v.5.0.0 [@Huerta-Cepas2019]. It seemed quite difficult to find a complete list of all data regarding viruses in the database apart from possibly just looking at the last 28 entries in [EggNOG 5.0.0 downloads page](http://eggnog5.embl.de/app/home#/app/downloads). When gathering that information following list of various virus data with different taxonomic ids could be obtained:

```{r, }
library(tidyverse)
library(kableExtra)
taxids <- read_csv("../analyses/HMM_scan_using_eggNOG_HMMs/virus_taxids.csv")
kable(taxids) %>%
  kable_styling(bootstrap_options = "striped", 
                full_width = F, 
                position = "center", 
                fixed_thead = T)
```

It seems difficult to figure out what nognames each taxid has so using the [RESTFul (web) API](http://eggnog5.embl.de/#/app/api) provided by EggNOG seems out of question. However, browsing [EggNOG database v. 5.0 data](http://eggnog5.embl.de/download/eggnog_5.0/per_tax_level/) on per taxa level, it seems that the data is stored in systematic way where it is essential to know the taxids. Therefore, let's now download the data using the txids. The following returns some strange output and will be discarded:

```{bash eval=FALSE, include=TRUE}
INPUT="../analyses/HMM_scan_using_eggNOG_HMMs/virus_taxids.csv"
URL_ROOT="http://eggnog5.embl.de/download/eggnog_5.0/per_tax_level/"
OUTPUT_DIR="../analyses/HMM_scan_using_eggNOG_HMMs/eggNOG_data"
OLDIFS=$IFS
IFS=','
[ ! -f $INPUT ] && { echo "$INPUT file not found"; exit 99; }
while read taxon_name taxid; do
  # Skip the header row with taxonomic name as the first item
  if [ $taxon_name != "taxonomic name" ]; then
    #echo "Others"
    TAXON=$(echo $taxon_name | sed -e "s/[[:space:]]/_/g")
    #echo $TAXON
    # Download annotations files

    #wget -c -O "$OUTPUT_DIR""$TAXON""_""$taxid""_annotations.tsv.gz" "$URL_ROOT""$taxid""/""$taxid""_annotations.tsv.gz"
    #echo $OUT   """_""$taxid""_annotations.tsv.gz"
    IFS=$OLDIFS
    echo "${OUTPUT_DIR}${TAXON}_${taxid}_annotations.tsv.gz" 
    #; ""$URL_ROOT""$taxid""/""$taxid""_annotations.tsv.gz"
    OLDIFS=$IFS
    IFS=','
    # Download hmms
    #wget -c -O "$OUTPUT_DIR""$TAXON""_""$taxid""_hmms.tar" "$URL_ROOT""$taxid""/""$taxid""_hmms.tar"
    #echo "$OUTPUT_DIR""$TAXON""_""$taxid""_hmms.tar ; " "$URL_ROOT""$taxid""/""$taxid""_hmms.tar"
  fi
done < $INPUT
IFS=$OLDIFS
```

Maybe another script might do the trick instead:

```{bash eval=FALSE, include=TRUE}
INPUT="../analyses/HMM_scan_using_eggNOG_HMMs/virus_taxids.csv"
URL_ROOT="http://eggnog5.embl.de/download/eggnog_5.0/per_tax_level/"
OUTPUT_DIR="../analyses/HMM_scan_using_eggNOG_HMMs/eggNOG_data/"
SCRIPT="../scripts/eggNOGdataDownloader.awk"

# Skip the header line
tail -n +2 $INPUT | awk -F, -v url="$URL_ROOT" -v output="$OUTPUT_DIR" -f "$SCRIPT"

```

Yes. The download succeeded!

Then we need to untar some of the downloads and ...

```{bash eval=FALSE, include=TRUE}
DATA="../analyses/HMM_scan_using_eggNOG_HMMs/eggNOG_data/"
OUTPUT="../analyses/HMM_scan_using_eggNOG_HMMs/eggNOG_data/HMMs/"

read -r -a TARs <<< $( find $DATA -name "*.tar" -and -type f -print0 | xargs -0 echo )
for TAR in "${TARs[@]}"; do
  tar -xvf $TAR -C "$OUTPUT"
done
```

unzip some others:

```{bash eval=FALSE, include=TRUE}
DATA="../analyses/HMM_scan_using_eggNOG_HMMs/eggNOG_data/"
gunzip "$DATA"*.tsv.gz
```

And lastly let's rearrange the files to own directories:

```{bash eval=FALSE, include=TRUE}
# Move tar files
DATA="../analyses/HMM_scan_using_eggNOG_HMMs/eggNOG_data/"
mv "$DATA"*.tar "$DATA""tars/"
# Move annotation files
mv "$DATA"*.tsv "$DATA""annotations/"
```



# Session info

```{r}
sessionInfo()
```

# References
